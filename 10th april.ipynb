{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059e2703-382c-44da-a117-d39869eefc80",
   "metadata": {},
   "source": [
    "# Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e740a-0691-40ac-8e03-c04960b8c892",
   "metadata": {},
   "source": [
    "## We are given: P(using health insurance plan) = 0.7, P(smoker | using health insurance plan) = 0.4\n",
    "## We want to find: P(smoker | using health insurance plan)\n",
    "## We can use Bayes' theorem to calculate this probability: P(smoker | using health insurance plan) = P(using health insurance plan | smoker) * P(smoker) / P(using health insurance plan)\n",
    "## We don't have direct information about P(using health insurance plan | smoker), but we can use the law of total probability to calculate it: P(using health insurance plan | smoker) = P(using health insurance plan and smoker) / P(smoker)\n",
    "## We can rearrange the given information to find P(using health insurance plan and smoker): P(smoker | using health insurance plan) * P(using health insurance plan) = P(using health insurance plan and smoker)\n",
    "## Plugging in the values, we get: P(using health insurance plan and smoker) = 0.4 * 0.7 = 0.28\n",
    "## We can find P(smoker) using the law of total probability: P(smoker) = P(smoker | using health insurance plan) * P(using health insurance plan) + P(smoker | not using health insurance plan) * P(not using health insurance plan)\n",
    "## We don't have direct information about P(smoker | not using health insurance plan), but we can assume that it is the same as P(smoker | using health insurance plan). This is not necessarily true in general, but it is a reasonable assumption to make for this problem.\n",
    "## Plugging in the values, we get: P(smoker) = 0.4 * 0.7 + 0.4 * 0.3 = 0.28 + 0.12 = 0.4\n",
    "## Finally, we can plug in all the values into Bayes' theorem to find the probability we want: P(smoker | using health insurance plan) = (0.28 / 0.4) * 0.4 / 0.7 â‰ˆ 0.8\n",
    "## Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is approximately 0.8, or 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93cbc2e-bab8-497f-bc31-90ed07c20598",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac3685-3867-434e-be6c-e5999e39ecaa",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes and Multinomial Naive Bayes are two types of Naive Bayes classifiers that are commonly used for text classification tasks. The main difference between the two lies in the way they represent the data.\n",
    "## Bernoulli Naive Bayes assumes that each feature (or word) is binary, meaning that it is either present or absent in the document. For example, in a spam classification task, the features could be the presence or absence of certain words in the email. If a particular word is present in the email, its corresponding feature value would be 1, and if it is absent, the value would be 0. Bernoulli Naive Bayes calculates the likelihood of each feature given the class, and uses these probabilities to classify new instances.\n",
    "## Multinomial Naive Bayes, on the other hand, assumes that each feature represents a count of the number of times it occurs in the document. For example, in a sentiment analysis task, the features could be the frequency of certain words in a given review. If a particular word occurs twice in the review, its corresponding feature value would be 2. Multinomial Naive Bayes calculates the likelihood of each feature given the class, taking into account the frequency of each feature, and uses these probabilities to classify new instances.\n",
    "## In summary, the main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the way they represent the data - binary for Bernoulli and count-based for Multinomial. The choice between the two depends on the specific problem at hand and the characteristics of the data. If the data is binary in nature and the focus is on presence/absence of features, Bernoulli Naive Bayes may be more appropriate. If the data represents frequency counts, Multinomial Naive Bayes may be a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0ec75-d297-47db-9d5c-30135e721147",
   "metadata": {},
   "source": [
    "# Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5307a2e1-649b-401a-9df5-6eeec9aaa112",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes assumes that each feature is binary, meaning that it is either present or absent in the document. If a feature is missing (i.e., its value is unknown), it can be treated as if it is absent. This is known as the \"missing-at-random\" assumption, which assumes that the probability of a missing value is independent of the true value of the feature, given the class.\n",
    "## In practice, when using Bernoulli Naive Bayes for classification, missing values can be handled by simply ignoring them and treating them as if they were absent. This is because the probability of a missing value occurring in a document is relatively low, and so the impact of missing values on classification accuracy is usually small. However, if missing values occur frequently or are systematically related to the class variable, the model's accuracy may be compromised.\n",
    "## In cases where missing values occur frequently or are systematically related to the class variable, more advanced techniques can be used to handle missing values. For example, imputation methods can be used to estimate missing values based on other features in the dataset, or more complex models such as Decision Trees or Random Forests can be used to handle missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0e345-da60-467c-a4cd-5faac6193878",
   "metadata": {},
   "source": [
    "# Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd8991-3c93-470c-a8f7-23e7dbac817a",
   "metadata": {},
   "source": [
    "## Yes, Gaussian Naive Bayes can be used for multi-class classification. Gaussian Naive Bayes is a probabilistic algorithm that can be used for classification problems where the input features are continuous-valued. In the case of multi-class classification, Gaussian Naive Bayes assumes that the conditional probability distribution of the input features given the class label follows a Gaussian distribution. It then calculates the posterior probability of each class given the input features using Bayes' theorem and chooses the class with the highest probability as the predicted class. One way to handle multi-class classification using Gaussian Naive Bayes is to use the \"one-vs-all\" or \"one-vs-rest\" approach. In this approach, a separate binary classification model is trained for each class label. Each binary classifier predicts whether an input belongs to that class or not. The final prediction is made by selecting the class with the highest probability among all the binary classifiers.\n",
    "## Scikit-learn provides an implementation of Gaussian Naive Bayes in its GaussianNB class, which supports multi-class classification. You can use the fit method to train the model on the training data and the predict method to make predictions on new data. Here is an example code snippet in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23836bbb-34b5-4779-b516-de8e3becea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset and split it into training and test sets\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Gaussian Naive Bayes classifier on the training set\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the test set\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Accuracy on test set: {:.2f}\".format(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e588154-add5-4916-9070-9ae05dd734eb",
   "metadata": {},
   "source": [
    "## In this example, we load the iris dataset and split it into training and test sets using train_test_split. We then train a Gaussian Naive Bayes classifier on the training set using GaussianNB and make predictions on the test set using the predict method. Finally, we calculate the accuracy of the model on the test set using the score method. This code can be easily extended to handle multi-class classification problems with more than two classes by using the \"one-vs-all\" approach described above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281482a-d8bc-4c26-9481-3c852f607447",
   "metadata": {},
   "source": [
    "# Q5. Assignment: Implementation:Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d490360-68bc-4651-99b2-0a1c80ac1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a60ba47-ed90-467d-aeee-d61578b30221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spambase.data')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cded13a8-d9d5-494e-bd35-d8347ef8c6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "0.64      0\n",
       "0.64.1    0\n",
       "0.1       0\n",
       "0.32      0\n",
       "0.2       0\n",
       "0.3       0\n",
       "0.4       0\n",
       "0.5       0\n",
       "0.6       0\n",
       "0.7       0\n",
       "0.64.2    0\n",
       "0.8       0\n",
       "0.9       0\n",
       "0.10      0\n",
       "0.32.1    0\n",
       "0.11      0\n",
       "1.29      0\n",
       "1.93      0\n",
       "0.12      0\n",
       "0.96      0\n",
       "0.13      0\n",
       "0.14      0\n",
       "0.15      0\n",
       "0.16      0\n",
       "0.17      0\n",
       "0.18      0\n",
       "0.19      0\n",
       "0.20      0\n",
       "0.21      0\n",
       "0.22      0\n",
       "0.23      0\n",
       "0.24      0\n",
       "0.25      0\n",
       "0.26      0\n",
       "0.27      0\n",
       "0.28      0\n",
       "0.29      0\n",
       "0.30      0\n",
       "0.31      0\n",
       "0.33      0\n",
       "0.34      0\n",
       "0.35      0\n",
       "0.36      0\n",
       "0.37      0\n",
       "0.38      0\n",
       "0.39      0\n",
       "0.40      0\n",
       "0.41      0\n",
       "0.42      0\n",
       "0.43      0\n",
       "0.778     0\n",
       "0.44      0\n",
       "0.45      0\n",
       "3.756     0\n",
       "61        0\n",
       "278       0\n",
       "1         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95b75b2-efa6-4388-b768-c2f3927fa682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4600 non-null   float64\n",
      " 1   0.64    4600 non-null   float64\n",
      " 2   0.64.1  4600 non-null   float64\n",
      " 3   0.1     4600 non-null   float64\n",
      " 4   0.32    4600 non-null   float64\n",
      " 5   0.2     4600 non-null   float64\n",
      " 6   0.3     4600 non-null   float64\n",
      " 7   0.4     4600 non-null   float64\n",
      " 8   0.5     4600 non-null   float64\n",
      " 9   0.6     4600 non-null   float64\n",
      " 10  0.7     4600 non-null   float64\n",
      " 11  0.64.2  4600 non-null   float64\n",
      " 12  0.8     4600 non-null   float64\n",
      " 13  0.9     4600 non-null   float64\n",
      " 14  0.10    4600 non-null   float64\n",
      " 15  0.32.1  4600 non-null   float64\n",
      " 16  0.11    4600 non-null   float64\n",
      " 17  1.29    4600 non-null   float64\n",
      " 18  1.93    4600 non-null   float64\n",
      " 19  0.12    4600 non-null   float64\n",
      " 20  0.96    4600 non-null   float64\n",
      " 21  0.13    4600 non-null   float64\n",
      " 22  0.14    4600 non-null   float64\n",
      " 23  0.15    4600 non-null   float64\n",
      " 24  0.16    4600 non-null   float64\n",
      " 25  0.17    4600 non-null   float64\n",
      " 26  0.18    4600 non-null   float64\n",
      " 27  0.19    4600 non-null   float64\n",
      " 28  0.20    4600 non-null   float64\n",
      " 29  0.21    4600 non-null   float64\n",
      " 30  0.22    4600 non-null   float64\n",
      " 31  0.23    4600 non-null   float64\n",
      " 32  0.24    4600 non-null   float64\n",
      " 33  0.25    4600 non-null   float64\n",
      " 34  0.26    4600 non-null   float64\n",
      " 35  0.27    4600 non-null   float64\n",
      " 36  0.28    4600 non-null   float64\n",
      " 37  0.29    4600 non-null   float64\n",
      " 38  0.30    4600 non-null   float64\n",
      " 39  0.31    4600 non-null   float64\n",
      " 40  0.33    4600 non-null   float64\n",
      " 41  0.34    4600 non-null   float64\n",
      " 42  0.35    4600 non-null   float64\n",
      " 43  0.36    4600 non-null   float64\n",
      " 44  0.37    4600 non-null   float64\n",
      " 45  0.38    4600 non-null   float64\n",
      " 46  0.39    4600 non-null   float64\n",
      " 47  0.40    4600 non-null   float64\n",
      " 48  0.41    4600 non-null   float64\n",
      " 49  0.42    4600 non-null   float64\n",
      " 50  0.43    4600 non-null   float64\n",
      " 51  0.778   4600 non-null   float64\n",
      " 52  0.44    4600 non-null   float64\n",
      " 53  0.45    4600 non-null   float64\n",
      " 54  3.756   4600 non-null   float64\n",
      " 55  61      4600 non-null   int64  \n",
      " 56  278     4600 non-null   int64  \n",
      " 57  1       4600 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f016106f-a080-4ea5-a2a9-2f7659be95b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.iloc[:,:-1]\n",
    "y=data['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a2ed7bd-90d8-46f4-af1b-fe52fdd72619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size= 0.3, random_state=42)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5333c983-13e2-4356-af00-c429af2c5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automate the model training process\n",
    "models= {\n",
    "    'Naive Bayes(M)' : MultinomialNB(),\n",
    "    'Naive Bayes(G)': GaussianNB(),\n",
    "    'Naive Bayes(B)' : BernoulliNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00a92164-1645-4e4d-ac6e-860aa1962a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train,y_train, X_test,y_test,models):\n",
    "    report = {}\n",
    "    for i in range(len(models)):\n",
    "        model = list(models.values())[i]\n",
    "        # model training\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        #predict test data\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        #accuracy\n",
    "        test_model_score = accuracy_score(y_test,y_test_pred)\n",
    "        \n",
    "        report[list(models.keys())[i]] = test_model_score\n",
    "        \n",
    "        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad36cfc1-ef66-4a0b-a52d-c71c90bc50c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naive Bayes(M)': 0.7717391304347826,\n",
       " 'Naive Bayes(G)': 0.8181159420289855,\n",
       " 'Naive Bayes(B)': 0.8717391304347826}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train,y_train, X_test,y_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66d497a3-300f-4ab0-9c31-cd9c60b19932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       803\n",
      "           1       0.91      0.88      0.90       577\n",
      "\n",
      "    accuracy                           0.91      1380\n",
      "   macro avg       0.91      0.91      0.91      1380\n",
      "weighted avg       0.91      0.91      0.91      1380\n",
      "\n",
      "[[753  50]\n",
      " [ 68 509]]\n",
      "0.9144927536231884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='linear')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7009cb46-8f69-4d16-92db-20241e0b909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test,y_pred)\n",
    "TP=con_mat[0][0]\n",
    "FP = con_mat[1][0]\n",
    "FN = con_mat[1][1]\n",
    "FP = con_mat[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed32db3e-3083-47bb-b960-8ce41d5013e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (TP\u001b[38;5;241m+\u001b[39m\u001b[43mTN\u001b[49m)\u001b[38;5;241m/\u001b[39m(TP\u001b[38;5;241m+\u001b[39mTN\u001b[38;5;241m+\u001b[39mFP\u001b[38;5;241m+\u001b[39mFN)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n\u001b[1;32m      3\u001b[0m precision \u001b[38;5;241m=\u001b[39m TP\u001b[38;5;241m/\u001b[39m(TP\u001b[38;5;241m+\u001b[39mFP)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TN' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "print(accuracy)\n",
    "precision = TP/(TP+FP)\n",
    "print(precision)\n",
    "recall = TP/(TP + FN)\n",
    "print(recall)\n",
    "F1_score= 2*precision*recall/(precision+recall)\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608fa0d-279c-452b-8ca3-7db85513b89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
